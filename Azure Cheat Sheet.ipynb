{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976b07c0-5e8e-48e6-85d1-ac49165a566c",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:'Glacial Indifference', sans-serif; font-size:32px; text-align:center; background-color:teal; color:white; border-radius: 15px 50px; \">Azure ML</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed5654-79f4-424e-ae10-1ab95c07b17a",
   "metadata": {},
   "source": [
    "> Disclaimer: This notebook summarizes Python SDK common code commands used in Azure Machine Learning platform. All original contents belong to Microsoft and are accessible at [Microsoft Learn](https://learn.microsoft.com/en-us/training/courses/dp-100t01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7318e32a-ae49-4195-9aad-682420b4d3c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a3244-5902-4265-abf5-33cbcad89be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32335f2b-274d-47cc-b504-d3fbe3e6a10b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76985864-47c4-4253-841c-ead76b045eed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95d036-e4ac-47c4-825b-a609e5f70fb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create a workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e3431-e3a9-4699-9e88-c63755bbbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Workspace\n",
    "\n",
    "workspace_name = \"mlw-example\"\n",
    "\n",
    "ws_basic = Workspace(\n",
    "    name=workspace_name,\n",
    "    location=\"eastus\",\n",
    "    display_name=\"Basic workspace-example\",\n",
    "    description=\"This example shows how to create a basic workspace\",\n",
    ")\n",
    "ml_client.workspaces.begin_create(ws_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce0450-294e-4d3d-9938-90c3f2eb099e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Connect to a workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a2a46-ec6c-43d1-b60b-1ea13abe7b58",
   "metadata": {},
   "source": [
    "### Step 1: Define the authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed675d3-e532-4d63-81f5-eb5b776506d7",
   "metadata": {},
   "source": [
    "By connecting, we're authenticating your environment to interact with the workspace to create and manage assets and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c81c9-dd26-43b2-9501-c09f96218622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466cb4c5-8798-417b-9680-d14e3670006f",
   "metadata": {},
   "source": [
    "While working with a compute instance, managed by Azure Machine Learning, we can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739986a4-6d42-43ec-9c03-e88bb43723f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f848fcf-0b80-4b75-8648-4f6157096192",
   "metadata": {},
   "source": [
    "### Step 2: Connect to workspace on submitting job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73d170-be5a-425d-89fa-ccb54a92b4fb",
   "metadata": {},
   "source": [
    "After defining the authentication, we need to call MLClient for the environment to connect to the workspace. We'll call MLClient anytime we want to create or update an asset or resource in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0eed05-7140-4fef-9937-e06274c8be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    experiment_name=\"train-model\"\n",
    ")\n",
    "\n",
    "# connect to workspace and submit job\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f08507-8308-4776-9af4-ca44a48c8568",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c93d587-7eab-4a38-a97a-290184d1463d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbe3a4-7351-4148-adb6-8802704ebc5b",
   "metadata": {},
   "source": [
    "To work with data in Azure Machine Learning, we can access data by using **Uniform Resource Identifiers** (URIs). \n",
    "\n",
    "When we work with a data source or a specific file or folder **repeatedly**, we can create **datastores** and **data assets** within the Azure Machine Learning workspace. Datastores and data assets allow we to securely store the connection information to your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd060b-ff10-4364-8daa-7e2fb9482583",
   "metadata": {},
   "source": [
    "## Create a datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9213b345-a0fc-4e8a-8bff-2bdd81b153cb",
   "metadata": {},
   "source": [
    "**Definition**: In Azure Machine Learning, datastores are abstractions for cloud data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed670d1-9d2d-436f-b23d-5ce53fa3242a",
   "metadata": {},
   "source": [
    "Whenever we want to connect another Azure storage service with the Azure Machine Learning workspace, we can create a datastore. Note that creating a datastore, creates the connection between your workspace and the storage, it doesn't create the storage service itself.\n",
    "\n",
    "To create a datastore and connect to a (already existing) storage, we'll need to specify:\n",
    "\n",
    "- The class to indicate with what type of storage service we want to connect. The example below connects to a Blob storage (`AzureBlobDatastore`).\n",
    "- `name`: The display name of the datastore in the Azure Machine Learning workspace.\n",
    "- `description`: Optional description to provide more information about the datastore.\n",
    "- `account_name`: The name of the Azure Storage Account.\n",
    "- `container_name`: The name of the container to store blobs in the Azure Storage Account.\n",
    "- `credentials`: Provide the method of authentication and the credentials to authenticate. The example below uses an account key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd36d3f0-eab2-4f37-9306-a970d9ccb4ef",
   "metadata": {},
   "source": [
    "Below is an example when we want to create a datastore to connect to an Azure Blob Storage container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf70b38-5913-4fa9-82fd-c91f4f9f2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore = AzureBlobDatastore(\n",
    "    \t\t\tname = \"blob_example\",\n",
    "    \t\t\tdescription = \"Datastore pointing to a blob container\",\n",
    "    \t\t\taccount_name = \"mytestblobstore\",\n",
    "    \t\t\tcontainer_name = \"data-container\",\n",
    "    \t\t\tcredentials = AccountKeyConfiguration(\n",
    "        \t\t\taccount_key=\"XXXxxxXXXxXXXXxxXXX\"\n",
    "    \t\t\t),\n",
    ")\n",
    "ml_client.create_or_update(blob_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535dad4c-fbdd-46de-9a85-2cbdd635843d",
   "metadata": {},
   "source": [
    "Alternatively, we can create a datastore to connect to an Azure Blob Storage container by using a SAS token to authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f5c95-b83c-457f-bcbb-1a9bb42f0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore = AzureBlobDatastore(\n",
    "name=\"blob_sas_example\",\n",
    "description=\"Datastore pointing to a blob container\",\n",
    "account_name=\"mytestblobstore\",\n",
    "container_name=\"data-container\",\n",
    "credentials=SasTokenConfiguration(\n",
    "sas_token=\"?xx=XXXX-XX-XX&xx=xxxx&xxx=xxx&xx=xxxxxxxxxxx&xx=XXXX-XX-XXXXX:XX:XXX&xx=XXXX-XX-XXXXX:XX:XXX&xxx=xxxxx&xxx=XXxXXXxxxxxXXXXXXXxXxxxXXXXXxxXXXXXxXXXXxXXXxXXxXX\"\n",
    "),\n",
    ")\n",
    "ml_client.create_or_update(blob_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1bb43-f334-4588-8aad-b7c4ce4ea756",
   "metadata": {},
   "source": [
    "To check all the available datastores, use `datastores.list()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca184f4b-4043-407f-8c32-5101581aab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = ml_client.datastores.list()\n",
    "for ds_name in stores:\n",
    "    print(ds_name.name)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844ca0e-0157-4194-8a7b-53525ef834ab",
   "metadata": {},
   "source": [
    "## Create a data asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f935e9c-9542-4b46-b217-ff639a8414f4",
   "metadata": {},
   "source": [
    "**Definition**: In Azure Machine Learning, data assets are references to where the data is stored, how to get access, and any other relevant metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc85b4-8869-416a-9892-7df4ca034c7e",
   "metadata": {},
   "source": [
    "Data assets are most useful when executing machine learning tasks as Azure Machine Learning jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3fd32e-0272-4c68-98db-01e0c99e5899",
   "metadata": {},
   "source": [
    "To point to a specific folder or file in a datastore, we can create data assets. There are three types of data assets:\n",
    "\n",
    "- **URI_FILE** points to a specific file.\n",
    "- **URI_FOLDER** points to a specific folder.\n",
    "- **MLTABLE** points to a MLTable file which specifies how to read one or more files within a folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79267f-83fd-416a-92b0-4f610c23ccbf",
   "metadata": {},
   "source": [
    "### Create a URI file data asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e340f-380a-43e8-b409-defe4a19961d",
   "metadata": {},
   "source": [
    "The supported paths we can use when creating a URI file data asset are:\n",
    "\n",
    "- Local: `./<path>`\n",
    "- Azure Blob Storage: `wasbs://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>`\n",
    "- Azure Data Lake Storage (Gen 2): `abfss://<file_system>@<account_name>.dfs.core.windows.net/<folder>/<file>`\n",
    "- Datastore: `azureml://datastores/<datastore_name>/paths/<folder>/<file>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc46dd9-0fb6-48da-80ef-c2d0e64ae9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "my_path = '<supported-path>'\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"<description>\",\n",
    "    name=\"<name>\",\n",
    "    version=\"<version>\"\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2384f-c6ab-4097-bc04-9400a101ffc4",
   "metadata": {},
   "source": [
    "### Create a URI file data asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01163700-aafa-4212-8c1a-aaea7c340395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "my_path = '<supported-path>'\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"<description>\",\n",
    "    name=\"<name>\",\n",
    "    version='<version>'\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e0f28-da92-4f44-8ec4-a58c9d301279",
   "metadata": {},
   "source": [
    "### Create a MLTable data asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba08d5a-822d-4a1a-9d83-b46b3de328ac",
   "metadata": {},
   "source": [
    "A MLTable data asset allows we to point to tabular data. When we create a MLTable data asset, we specify the schema definition to read the data. Therefore, we want to use a MLTable data asset when the schema of your data is complex or changes frequently. Instead of changing how to read the data in every script that uses the data, we only have to change it in the data asset itself.\n",
    "\n",
    "For certain features in Azure Machine Learning, like Automated Machine Learning, we need to use a MLTable data asset, as Azure Machine Learning needs to know how to read the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687e8b3e-9644-4ceb-8966-788de0557c72",
   "metadata": {},
   "source": [
    "#### Step 1: Define the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43f351-13d0-45bc-88a0-7dbd4f3950cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a yml code, not Python\n",
    "type: mltable\n",
    "\n",
    "paths:\n",
    "  - pattern: ./*.txt\n",
    "transformations:\n",
    "  - read_delimited:\n",
    "      delimiter: ','\n",
    "      encoding: ascii\n",
    "      header: all_files_same_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7696875-867c-4ed1-8011-a9a4767acd9a",
   "metadata": {},
   "source": [
    "#### Step 2: Create a MLTable data asset with defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaaa1e4-7374-4192-8080-4fed64a80a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "my_path = '<path-including-mltable-file>'\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description=\"<description>\",\n",
    "    name=\"<name>\",\n",
    "    version='<version>'\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e683d0f-f953-475e-a65e-682a25dd8de1",
   "metadata": {},
   "source": [
    "### List all data assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa0752-eb7a-45f2-9be5-dab6acd5a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ml_client.data.list()\n",
    "for ds_name in datasets:\n",
    "    print(ds_name.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45946322-15ae-4fd9-9876-95ea0f21f2d6",
   "metadata": {},
   "source": [
    "### Parsing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fbe39-03bd-49c0-b237-fc9a6eed6463",
   "metadata": {},
   "source": [
    "When we parse the URI file, URI folder or MLTable data asset as input in an Azure Machine Learning job, we first need to read the data before we can work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fd74c-78a6-40eb-860b-48b58c286028",
   "metadata": {},
   "source": [
    "#### Parsing with URI file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab706d8-5afd-4316-ae72-f20516b2e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input_data\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "df = pd.read_csv(args.input_data)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2595a-681d-4c38-be96-649ab580ad7a",
   "metadata": {},
   "source": [
    "#### Parsing with URI folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe3af29-e983-4932-9279-68c4ae9b5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input_data\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_path = args.input_data\n",
    "all_files = glob.glob(data_path + \"/*.csv\")\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1eddb-ddf0-4cb1-aaa2-d52c39c6446c",
   "metadata": {},
   "source": [
    "#### Parsing with MLTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9f984-0be3-4e71-ae8c-79e363dbf485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import mltable\n",
    "import pandas\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input_data\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "tbl = mltable.load(args.input_data)\n",
    "df = tbl.to_pandas_dataframe()\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b9c7b-3dea-414f-8882-2adbc5f501e5",
   "metadata": {},
   "source": [
    "## Use data in a job (Complete example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a53ac7-4770-4033-93cc-31ea5fd87869",
   "metadata": {},
   "source": [
    "After using a notebook for experimentation. We can use scripts to train machine learning models. A script can be run as a job, and for each job we can specify inputs and outputs.\n",
    "\n",
    "We can use either **data assets** or **datastore paths** as inputs or outputs of a job.\n",
    "\n",
    "The example below creates the **move-data.py** script in the src folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eaf4aa-0261-489b-9051-cf72d6d044e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create a folder for the script files\n",
    "script_folder = 'src'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dcfdbc-2bd9-4525-858a-40fa004d6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/move-data.py\n",
    "# import libraries\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.input_data)\n",
    "\n",
    "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Count the rows and print the result\n",
    "    row_count = (len(df))\n",
    "    print('Analyzing {} rows of data'.format(row_count))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--input_data\", dest='input_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
    "                        type=str)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191991b-2409-4f2f-b663-056a9ef675ae",
   "metadata": {},
   "source": [
    "**Data asset:** We use URI file data asset with local file to point to the local diabetes.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3397cc-42c5-49dd-8bdf-90d1fac6699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "my_path = './data/diabetes.csv'\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
    "    name=\"diabetes-local\"\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98770f-4bdb-4ce1-85de-8b87b882021a",
   "metadata": {},
   "source": [
    "Finally, we submit a job that runs the **move-data.py** script, using the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f975e-f7cd-4815-9882-714ed509a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import command\n",
    "\n",
    "# configure input and output\n",
    "my_job_inputs = {\n",
    "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
    "}\n",
    "\n",
    "my_job_outputs = {\n",
    "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
    "}\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python move-data.py --input_data \n",
    "{{outputs.datastore_data}}\",\n",
    "    inputs=my_job_inputs,\n",
    "    outputs=my_job_outputs,\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"move-diabetes-data\",\n",
    "    experiment_name=\"move-diabetes-data\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9bcde8-2dba-4525-9d91-832bb33654f9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c9e878-5e46-4a63-a622-4317dd13ed6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Compute target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adba786-b421-464e-bb66-cacd72961ce8",
   "metadata": {},
   "source": [
    "**Definition**: In Azure Machine Learning, compute targets are physical or virtual computers on which jobs are run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8fdae-cb31-4b12-819d-391b2c9adaaf",
   "metadata": {},
   "source": [
    "## Compute instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9549ad-2f5c-4766-a079-bf0071da892f",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bee45-31ba-41b9-9404-ba520eccc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ComputeInstance\n",
    "\n",
    "ci_basic_name = \"basic-ci-12345\"\n",
    "ci_basic = ComputeInstance(\n",
    "    name=ci_basic_name, \n",
    "    size=\"STANDARD_DS3_v2\"\n",
    ")\n",
    "ml_client.begin_create_or_update(ci_basic).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91f519-1ac0-4270-82de-e43c77163c61",
   "metadata": {},
   "source": [
    "## Compute cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83ba7bb-301b-498a-a94d-91a622c1b042",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732e2ea-6fec-43df-92d0-c4ad60213213",
   "metadata": {},
   "source": [
    "When we create a compute cluster, there are three main parameters we need to consider:\n",
    "\n",
    "- `size`: Specifies the virtual machine type of each node within the compute cluster. Based on the sizes for virtual machines in Azure. Next to size, we can also specify whether we want to use CPUs or GPUs.\n",
    "- `max_instances`: Specifies the maximum number of nodes your compute cluster can scale out to. The number of parallel workloads your compute cluster can handle is analogous to the number of nodes your cluster can scale to.\n",
    "- `tier`: Specifies whether your virtual machines are low priority or dedicated. Setting to low priority can lower costs as we're not guaranteed availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160364f-0ae5-4a7e-8f62-f2d9959081c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cluster_basic = AmlCompute(\n",
    "    name=\"cpu-cluster\",\n",
    "    type=\"amlcompute\",\n",
    "    size=\"STANDARD_DS3_v2\",\n",
    "    location=\"westus\",\n",
    "    min_instances=0,\n",
    "    max_instances=2,\n",
    "    idle_time_before_scale_down=120,\n",
    "    tier=\"low_priority\",\n",
    ")\n",
    "ml_client.begin_create_or_update(cluster_basic).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee81f17-e766-4179-8328-e3f3009f8b3b",
   "metadata": {},
   "source": [
    "### Modify the configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4368fa92-60c8-4050-8994-f572819dc9a9",
   "metadata": {},
   "source": [
    "Once created, we can only change the configuration for:\n",
    "\n",
    "- `min_instances`: Minimum number of nodes\n",
    "- `max_instances`: Maximum number of nodes\n",
    "- `idle_time_before_scale_down`: Idle time before scale down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971fa369-90be-450f-901c-7db89d70ccdd",
   "metadata": {},
   "source": [
    "For example, to change `max_instances` to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6d42ad-169a-4a14-ba03-f14335992f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cluster_scale = AmlCompute(\n",
    "    name=\"aml-cluster\",\n",
    "    max_instances=2,\n",
    ")\n",
    "ml_client.begin_create_or_update(cluster_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea24de4-bcaf-45fd-b7b8-d1b8419d9550",
   "metadata": {},
   "source": [
    "### Check the configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e893585-2003-41f4-81f8-84e2e87852fa",
   "metadata": {},
   "source": [
    "When the compute cluster is updated, we can verify its configuration by printing its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70653584-3971-47a4-9136-f42fc10cd103",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster = ml_client.compute.get(\"aml-cluster\")\n",
    "\n",
    "print (\n",
    "        f\"AMLCompute with name {cpu_cluster.name} has a maximum of {cpu_cluster.max_instances} nodes\"\n",
    "    )\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde4bec7-04ec-4a0e-baff-73304fdd6ccb",
   "metadata": {},
   "source": [
    "### Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4407e5e-1506-4b98-b46f-ae65f6537ea4",
   "metadata": {},
   "source": [
    "There are three main scenarios in which we can use a compute cluster:\n",
    "\n",
    "- Running a pipeline job we built in the Designer.\n",
    "- Running an Automated Machine Learning job.\n",
    "- Running a script as a job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0eb5e-bb45-442b-880f-62256e0d5994",
   "metadata": {},
   "source": [
    "Example of using compute cluster to run a script as a command job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4d9ac-7564-4a0a-8d46-28fcf54874fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    display_name=\"train-with-cluster\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39641a4-8486-4d98-8a95-e89d592c1dcf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9751fa56-770e-41cf-ac1d-87166425a754",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7719aa8-096e-4863-a6c3-4b19e88b1aa8",
   "metadata": {},
   "source": [
    "As a data scientist, we want to write code that works in any development environment. Whether we're using local or cloud compute, the code should successfully execute to train a machine learning model for example.\n",
    "\n",
    "To run code, we need to ensure necessary packages, libraries, and dependencies are installed on the compute we use to run the code. In Azure Machine Learning, environments list and store the necessary packages that we can reuse across compute targets. Azure Machine Learning builds environment definitions into Docker images and conda environments. When we use an environment, Azure Machine Learning builds the environment on the Azure Container registry associated with the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f74a8-00a3-4071-a24e-603fc4c024d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the environments using the Python SDK:\n",
    "envs = ml_client.environments.list()\n",
    "for env in envs:\n",
    "    print(env.name)\n",
    "\n",
    "# Review the details of a specific environment\n",
    "env = ml_client.environments.get(name=\"my-environment\", version=\"1\")\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969058ed-909a-4be2-b1ec-259ea74d4d68",
   "metadata": {},
   "source": [
    "## Curated environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f220d-c9ed-4764-b78d-9957b8301364",
   "metadata": {},
   "source": [
    "**Definition**: Curated environments are prebuilt environments for the most common machine learning workloads, available in your workspace by default. Curated environments use the prefix **AzureML-** and are designed to provide for scripts that use popular machine learning frameworks and tooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34d2a9-d26d-4ae3-881a-04cc9ded4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the description and tags of a curated environment with the Python SDK: \n",
    "env = ml_client.environments.get(\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=44)\n",
    "print(env. description, env.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa43289-0e88-4ed6-b6a0-c7cd8b68295d",
   "metadata": {},
   "source": [
    "### Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25fb2a-78d8-4742-8a48-fdd3a3dcc069",
   "metadata": {},
   "source": [
    "To specify which environment we want to use to run your script, we reference an environment using the `<curated-environment-name>:<version>` or `<curated-environment-name>@latest` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5db59a-518f-4634-a521-b3e708d23184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"train-with-curated-environment\",\n",
    "    experiment_name=\"train-with-curated-environment\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fdb6a1-4a02-4e5d-88da-01aae31a79bb",
   "metadata": {},
   "source": [
    "## Custom environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb3f6d-f26c-4845-bb28-8cacd11ee866",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087061d-c784-4c55-ad26-c1427d024a86",
   "metadata": {},
   "source": [
    "#### Option 1: Using Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9f767-63b3-4392-bc08-ea0ac4067ae4",
   "metadata": {},
   "source": [
    "Docker images can be hosted in a public registry like [Docker Hub](https://hub.docker.com/) or privately stored in an Azure Container registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea89674-0a79-4888-893c-5c803d0ac878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_image = Environment(\n",
    "    image=\"pytorch/pytorch:latest\",\n",
    "    name=\"public-docker-image-example\",\n",
    "    description=\"Environment created from a public Docker image.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423215b-289e-4b47-83ec-cb2bfe2a3372",
   "metadata": {},
   "source": [
    "Alternatively, we can also use the Azure Machine Learning base images to create an environment (which are similar to the images used by curated environments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d571f-dbb9-4f38-951d-036d18ae488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_image = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    name=\"aml-docker-image-example\",\n",
    "    description=\"Environment created from a Azure ML Docker image.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159e175-9c0f-49d5-bf48-9a835ef71792",
   "metadata": {},
   "source": [
    "#### Option 2: Using a conda specification file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0efd29-c3a4-4fe4-99f9-bf5297c2c6b6",
   "metadata": {},
   "source": [
    "Though Docker images contain all necessary packages when working with a specific framework, it may be that we need to include other packages to run your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a6a47-ad0c-4c2f-a2c6-61000f6cf34c",
   "metadata": {},
   "source": [
    "##### Step 1: Create conda specification yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c8128-0a51-482e-b174-709f58287088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a yml code, not Python\n",
    "name: basic-env-cpu\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.7\n",
    "  - scikit-learn\n",
    "  - pandas\n",
    "  - numpy\n",
    "  - matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f480c-af4e-42b9-9387-d875c3348561",
   "metadata": {},
   "source": [
    "##### Step 2: Create an environment using yaml conda specification file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a7bb3-a330-4989-918c-28d9a7adcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    conda_file=\"./conda-env.yml\",\n",
    "    name=\"docker-image-plus-conda-example\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc4398-c947-4b0d-a739-c81df7daf1c6",
   "metadata": {},
   "source": [
    "#### Option 3: Using Docker image as base environemnt, and add some additional packages using conda specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee6e63-fc4c-49cb-830a-735f5c02400c",
   "metadata": {},
   "source": [
    "We simply use both parameters `image` and `conda_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abdaf44-5e2f-4029-8e36-05e28d13737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    conda_file=\"./conda-env.yml\",\n",
    "    name=\"docker-image-plus-conda-example\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9d234-347b-4393-8734-237437769711",
   "metadata": {},
   "source": [
    "### Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa73b4-93ff-484c-afd4-a5715e767cd4",
   "metadata": {},
   "source": [
    "Similarly to curated environment, to specify which environment we want to use to run your script, we reference an environment using the `<environment-name>:<version>` or `<environment-name>@latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b86c1-71e1-4678-89b3-383fdb0c966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\r\n",
    "\r\n",
    "# configure job\r\n",
    "job = command(\r\n",
    "    code=\"./src\",\r\n",
    "    command=\"python train.py\",\r\n",
    "    environment=\"docker-image-plus-conda-example:1\",\r\n",
    "    compute=\"aml-cluster\",\r\n",
    "    display_name=\"train-custom-env\",\r\n",
    "    experiment_name=\"train-custom-env\"\r\n",
    ")\r\n",
    "\r\n",
    "# submit job\r\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f77cf-6959-4900-8e6c-a42abf8e8b6c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4efffcb-650c-457e-a42e-867bdaa35970",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Automated Machine Learning (AutoML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae05553-9cc3-43f2-8166-a986288dcb93",
   "metadata": {},
   "source": [
    "## Preprocess data and configure featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e8be8-9c61-4e38-875d-c31b020a7c86",
   "metadata": {},
   "source": [
    "In order for AutoML to understand how to read the data, we need to create a **MLTable data asset** that includes the schema of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bf3c6-18c3-46dc-95e9-3f28c5637ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "my_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml:input-data-automl:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ac778-ba64-4af3-a42f-a86103ac67e5",
   "metadata": {},
   "source": [
    "AutoML applies scaling and normalization to numeric data automatically, helping prevent any large-scale features from dominating training. During an AutoML experiment, multiple scaling or normalization techniques will be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594ebe4-64bc-4293-b109-140dbef19450",
   "metadata": {},
   "source": [
    "Other optional featurization:\n",
    "- Missing value imputation to eliminate nulls in the training dataset.\n",
    "- Categorical encoding to convert categorical features to numeric indicators.\n",
    "- Dropping high-cardinality features, such as record IDs.\n",
    "- Feature engineering (for example, deriving individual date parts from DateTime features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92564789-6d26-496b-ae44-8faeeca68c89",
   "metadata": {},
   "source": [
    "## AutoML experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c0104-983c-49e1-9334-6bc822384d68",
   "metadata": {},
   "source": [
    "### Configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e95c9-8801-403b-9d9b-b2320df49f09",
   "metadata": {},
   "source": [
    "When we use the Python SDK (v2) to configure an AutoML experiment or job, we configure the experiment using the `automl` class. For classification, we'll use the `automl.classification` function as shown in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba3d13e-c450-40ac-9520-806e3693450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import automl\n",
    "\n",
    "# configure the classification job\n",
    "classification_job = automl.classification(\n",
    "    compute=\"aml-cluster\",\n",
    "    experiment_name=\"auto-ml-class-dev\",\n",
    "    training_data=my_training_data_input,\n",
    "    target_column_name=\"Diabetic\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    n_cross_validations=5,\n",
    "    enable_model_explainability=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ef92c-7ab5-497b-9886-6446f8559011",
   "metadata": {},
   "source": [
    "Parameters explaination:\n",
    "\n",
    "- Uses the compute cluster named `aml-cluster`\n",
    "- Sets `Diabetic` as the target column\n",
    "- Sets `accuracy` as the primary metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb38640-e797-4989-bc5b-33ca3a4542cd",
   "metadata": {},
   "source": [
    "**Note**: For a full list of primary metric, use the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882fadf-0505-4c6a-a1d5-c4080a2c7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.automl import ClassificationPrimaryMetrics\n",
    " \n",
    "list(ClassificationPrimaryMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c080ba0-98b0-4103-b9c7-b06812d95918",
   "metadata": {},
   "source": [
    "### Set the limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ce774-760e-440f-a284-6e809ad1ef75",
   "metadata": {},
   "source": [
    "To minimize costs and time spent on training, we can set limits to an AutoML experiment or job by using set_limits()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ae30f-3ad1-418d-a250-ba4731e9a171",
   "metadata": {},
   "source": [
    "There are several options to set limits to an AutoML experiment:\n",
    "\n",
    "- `timeout_minutes`: Number of minutes after which the complete AutoML experiment is terminated.\n",
    "- `trial_timeout_minutes`: Maximum number of minutes one trial can take.\n",
    "- `max_trials`: Maximum number of trials, or models that will be trained.\n",
    "- `enable_early_termination`: Whether to end the experiment if the score isn't improving in the short term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9669c-441d-4067-bff9-498e40949df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_job.set_limits(\n",
    "    timeout_minutes=60, \n",
    "    trial_timeout_minutes=20, \n",
    "    max_trials=5,\n",
    "    enable_early_termination=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e7eb9-3ac0-47a0-9843-03cdcba6b847",
   "metadata": {},
   "source": [
    "Parameters explaination:\n",
    "- Times out after `60` minutes of total training time\n",
    "- Trains a maximum of `5` models\n",
    "- No model will be trained with the `LogisticRegression` algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d242bc-11b7-417f-9745-83cf3ebf425e",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd83c27-bee6-4d77-8a04-3beaf37de109",
   "metadata": {},
   "source": [
    "To submit, we use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6cdb5a-7862-4569-8f3b-1a29afa2b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    classification_job\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d4759-8331-49e2-bb61-d47b439d368a",
   "metadata": {},
   "source": [
    "To monitor AutoML job runs in Azure ML studio, we can use the code below to get the direct link to the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca74cf-9751-4aed-b677-782a39489a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875cdad1-62bd-42f0-a3ce-3488d45d5c11",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4092020-2858-4f87-87e0-812276e3229c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7235c-4572-45b2-ad7f-fc7eef825e28",
   "metadata": {},
   "source": [
    "**Definition**: MLflow is an open-source library for tracking and managing your machine learning experiments. In particular, **MLflow Tracking** is a component of MLflow that logs everything about the model we're training, such as **parameters**, **metrics**, and **artifacts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a678c-69ca-4727-9d7c-08b8c1e46e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up\n",
    "# On Azure ML\n",
    "import mlflow \n",
    "\n",
    "# On local device\n",
    "pip install mlflow\n",
    "pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdebc1ca-28c7-47a9-a92f-a0d9efb87c44",
   "metadata": {},
   "source": [
    "## Create an MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d101ffa-8f90-4647-9ab6-6bb93051c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "experiment_name = \"mlflow-experiment-diabetes\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be70d1-5737-4398-b9f7-8657e72f81df",
   "metadata": {},
   "source": [
    "## Train and track models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980410c-8573-4406-992f-7f8c862d17a9",
   "metadata": {},
   "source": [
    "We have 2 options:\n",
    "- Use autologging\n",
    "- Use custom logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1664c6d-dfd3-4250-a13d-7c31a0c08351",
   "metadata": {},
   "source": [
    "### Option 1: Autologging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a638e-8fcc-437f-a882-39a66855c8f6",
   "metadata": {},
   "source": [
    "To enable autologging, use `mlflow.sklearn.autolog()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d985e5d-f166-4a1e-8fcf-66e9f69a4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    model = LogisticRegression(C=1/0.1, solver=\"liblinear\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7090e2d-57c4-43af-855c-9ec98e0cf82a",
   "metadata": {},
   "source": [
    "#### Flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c53296-dba4-4e8e-bf0f-e1294f218756",
   "metadata": {},
   "source": [
    "**Definition**: A flavor is the machine learning library with which the model was created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67b68e9-faa0-408f-8bf1-19dd5d221268",
   "metadata": {},
   "source": [
    "The framework we use to train your model is automatically identified and included as the **flavor** of your model. \n",
    "\n",
    "Optionally, we can specify which flavor we want your model to be identified as by using `mlflow.<flavor>.autolog()`. Some common flavors that we can use with autologging are:\n",
    "- Keras: `mlflow.keras.autolog`\n",
    "- Scikit-learn: `mlflow.sklearn.autolog()`\n",
    "- LightGBM: `mlflow.lightgbm.autolog`\n",
    "- XGBoost: `mlflow.xgboost.autolog`\n",
    "- TensorFlow: `mlflow.tensorflow.autolog`\n",
    "- PyTorch: `mlflow.pytorch.autolog`\n",
    "- ONNX: `mlflow.onnx.autolog`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36503c5-193b-416f-81e8-3a7c99e6ed0f",
   "metadata": {},
   "source": [
    "### Option 2: Custom logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39001c-d14e-4009-b675-055d0abb1b3d",
   "metadata": {},
   "source": [
    "First, we disable autologging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785030e-c7eb-4fb8-9952-9e3b389c58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc74ab8-5696-4edc-8b31-7db3efbc4822",
   "metadata": {},
   "source": [
    "Common functions used with custom logging are:\n",
    "\n",
    "- `mlflow.log_param()`: Logs a single key-value parameter. Use this function for an input parameter we want to log.\n",
    "- `mlflow.log_metric()`: Logs a single key-value metric. Value must be a number. Use this function for any output we want to store with the run.\n",
    "- `mlflow.log_artifact()`: Logs a file. Use this function for any plot we want to log, save as image file first.\n",
    "- `mlflow.log_model()`: Logs a model. Use this function to create an MLflow model, which may include a custom signature, environment, and input examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473a059-a438-4f7c-ab1e-0280c25a73dd",
   "metadata": {},
   "source": [
    "The code below use custom logging to log one parameter, one metric and one artifact (a png file contains the ROC curve):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08ff73-de8a-494f-9e42-7e5c2102422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "\n",
    "    # plot ROC curve\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    # Plot the diagonal 50% line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # Plot the FPR and TPR achieved by our model\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.savefig(\"ROC-Curve.png\")\n",
    "\n",
    "    mlflow.log_param(\"estimator\", \"DecisionTreeClassifier\")\n",
    "    mlflow.log_metric(\"Accuracy\", acc)\n",
    "    mlflow.log_artifact(\"ROC-Curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a761868-81cc-49f4-9449-55e1315aa2d2",
   "metadata": {},
   "source": [
    "All the log can be found in Jobs page of Azure ML studio:\n",
    "- **Params** and **Metrics** in Overview\n",
    "- **Artifacts** in Outputs + logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbf4c8-1f56-4fe5-843f-c83e6b89e490",
   "metadata": {},
   "source": [
    "#### Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d24c14-bca3-4283-b2d9-ab35fa3a9008",
   "metadata": {},
   "source": [
    "As logging the model allows we to easily deploy the model, we may want to customize the model's expected inputs and outputs. The schemas of the expected inputs and outputs are defined as the **signature** in the MLmodel file. The signature is stored in `JSON` format in the MLmodel file, together with other metadata of the model. \r\n",
    "The model signature can be inferred from datasets or created manually by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33425970-35fd-4f18-a984-45e849d52bd8",
   "metadata": {},
   "source": [
    "##### Option 1: Infer signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed52f4c-564c-4000-a216-6cdcd34b6e0a",
   "metadata": {},
   "source": [
    "To log a model with a signature that is inferred from your training dataset and model predictions, we can use `infer_signature()`. For example, the following example takes the training dataset to infer the schema of the inputs, and the model's predictions to infer the schema of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b61cce-b5f6-4c19-9b28-72a07bc2962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_train = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "clf = RandomForestClassifier(max_depth=7, random_state=0)\n",
    "clf.fit(iris_train, iris.target)\n",
    "\n",
    "# Infer the signature from the training dataset and model's predictions\n",
    "signature = infer_signature(iris_train, clf.predict(iris_train))\n",
    "\n",
    "# Log the scikit-learn model with the custom signature\n",
    "mlflow.sklearn.log_model(clf, \"iris_rf\", signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033decce-304c-442e-9114-74977b0bd781",
   "metadata": {},
   "source": [
    "##### Option 2: Manually created signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da2db4-49e6-47d2-9698-0c34d2605964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "# Define the schema for the input data\n",
    "input_schema = Schema([\n",
    "  ColSpec(\"double\", \"sepal length (cm)\"),\n",
    "  ColSpec(\"double\", \"sepal width (cm)\"),\n",
    "  ColSpec(\"double\", \"petal length (cm)\"),\n",
    "  ColSpec(\"double\", \"petal width (cm)\"),\n",
    "])\n",
    "\n",
    "# Define the schema for the output data\n",
    "output_schema = Schema([ColSpec(\"long\")])\n",
    "\n",
    "# Create the signature object\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788c1e5-38cf-4831-aba9-9872f8000c87",
   "metadata": {},
   "source": [
    "## Register an MLflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf7f36-fd99-41e5-81dc-559013b5fa00",
   "metadata": {},
   "source": [
    "After training, we want to deploy a machine learning model in order to integrate the model with an application. In Azure Machine Learning, we can easily deploy a model to a batch or online endpoint when we register the model with MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e8e6c-afdd-4fb7-aeae-aa8f1dee5188",
   "metadata": {},
   "source": [
    "MLflow uses the MLModel format to store all relevant model assets in a folder or directory. One essential file in the directory is the `MLmodel` file. The `MLmodel` file is the single source of truth about how the model should be loaded and used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b09f7a-3c8f-4c3c-88dc-6203c2b14d91",
   "metadata": {},
   "source": [
    "The `MLmodel` file may include:\n",
    "\n",
    "- `artifact_path`: During the training job, the model is logged to this path.\n",
    "- `flavor`: The machine learning library with which the model was created.\n",
    "- `model_uuid`: The unique identifier of the registered model.\n",
    "- `run_id`: The unique identifier of job run during which the model was created.\n",
    "- `signature`: Specifies the schema of the model's inputs and outputs:\n",
    "    - `inputs`: Valid input to the model. For example, a subset of the training dataset.\n",
    "    - `outputs`: Valid model output. For example, model predictions for the input dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5eaf4-728f-4748-9bdc-90ca15798068",
   "metadata": {},
   "source": [
    "Here is an example of a MLmodel file created for a computer vision model trained with `fastai` may look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c46512-bc2f-4f16-937e-c32cb9afbe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a yml code, not Python\n",
    "artifact_path: classifier\n",
    "flavors:\n",
    "  fastai:\n",
    "    data: model.fastai\n",
    "    fastai_version: 2.4.1\n",
    "  python_function:\n",
    "    data: model.fastai\n",
    "    env: conda.yaml\n",
    "    loader_module: mlflow.fastai\n",
    "    python_version: 3.8.12\n",
    "model_uuid: e694c68eba484299976b06ab9058f636\n",
    "run_id: e13da8ac-b1e6-45d4-a9b2-6a0a5cfac537\n",
    "signature:\n",
    "  inputs: '[{\"type\": \"tensor\",\n",
    "             \"tensor-spec\": \n",
    "                 {\"dtype\": \"uint8\", \"shape\": [-1, 300, 300, 3]}\n",
    "           }]'\n",
    "  outputs: '[{\"type\": \"tensor\", \n",
    "              \"tensor-spec\": \n",
    "                 {\"dtype\": \"float32\", \"shape\": [-1,2]}\n",
    "            }]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6851eb6-08f2-4925-9e7f-0256325eea28",
   "metadata": {},
   "source": [
    "There are three types of models we can register:\n",
    "\n",
    "- **MLflow**: Model trained and tracked with MLflow. Recommended for standard use cases.\n",
    "- **Custom**: Model type with a custom standard not currently supported by Azure Machine Learning.\n",
    "- **Triton**: Model type for deep learning workloads. Commonly used for TensorFlow and PyTorch model deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180717ca-b65c-4400-bc80-2604b24311ba",
   "metadata": {},
   "source": [
    "To register a MLflow model, we first need to submit a training script as a command job. Turning back to our diabetes prediction model as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224d431-4145-4213-94a5-13beddbd1f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-signature.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-signature\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edbc2c0-0073-4cb9-920a-96962dd02fe5",
   "metadata": {},
   "source": [
    "Once the job is completed and the model is trained, use the job name to find the job run and register the model from its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1c21b-51c8-466d-a665-37b6ebfcec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "job_name = returned_job.name\n",
    "\n",
    "run_model = Model(\n",
    "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
    "    name=\"mlflow-diabetes\",\n",
    "    description=\"Model created from run.\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "# Uncomment after adding required details above\n",
    "ml_client.models.create_or_update(run_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447eb92-e6fb-4b79-8777-e5c5aeb10bf4",
   "metadata": {},
   "source": [
    "### A complete example of a trained and registered MLflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85b3b8-3c00-4b14-8993-789ff1e1e053",
   "metadata": {},
   "source": [
    "#### Case 1: Autologging with specified flavor (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275a4ee-ef0f-491c-8a6b-689c7b7ddc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train-model-sklearn.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main(args):\n",
    "    ### AUTOLOGGING AND SPECIFIED FLAVOR ###\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    eval_model(model, X_test, y_test)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    "\n",
    "    # calculate AUC\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "    print('AUC: ' + str(auc))\n",
    "\n",
    "    # plot ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    # Plot the diagonal 50% line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # Plot the FPR and TPR achieved by our model\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.savefig(\"ROC-Curve.png\") \n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca641ed3-19f3-4bbb-a191-1d25adf6fd40",
   "metadata": {},
   "source": [
    "#### Case 2: Custom logging with defined signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675b6b1-5f41-42e6-aecb-7f08d823b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train-model-signature.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "def main(args):\n",
    "    ### DISABLE AUTOLOGGING ###\n",
    "    mlflow.autolog(log_models=False)\n",
    "\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # evaluate model\n",
    "    y_hat = eval_model(model, X_test, y_test)\n",
    "\n",
    "    ### DEFINE SCHEMA ###\n",
    "    input_schema = Schema([\n",
    "    ColSpec(\"integer\", \"Pregnancies\"),\n",
    "    ColSpec(\"integer\", \"PlasmaGlucose\"),\n",
    "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
    "    ColSpec(\"integer\", \"TricepsThickness\"),\n",
    "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
    "    ColSpec(\"integer\", \"SerumInsulin\"),\n",
    "    ColSpec(\"double\", \"BMI\"),\n",
    "    ColSpec(\"double\", \"DiabetesPedigree\"),\n",
    "    ColSpec(\"integer\", \"Age\"),\n",
    "    ])\n",
    "\n",
    "    output_schema = Schema([ColSpec(\"boolean\")])\n",
    "\n",
    "    # Create the signature object\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    # manually log the model\n",
    "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    " \n",
    "    return y_hat\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308b568-d451-47f2-8365-111fbd6ad15f",
   "metadata": {},
   "source": [
    "Supposing that we move on with script 2, we can run the code below to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa7dc9a-64f9-44f5-b69d-af12acbbb661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-signature.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-signature\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c441b-2520-4b73-895d-93ec0f606c5a",
   "metadata": {},
   "source": [
    "Finally, we register the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c569970-4c49-4b82-bfce-0f60326902b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "job_name = returned_job.name\n",
    "\n",
    "run_model = Model(\n",
    "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
    "    name=\"mlflow-diabetes\",\n",
    "    description=\"Model created from run.\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "# Uncomment after adding required details above\n",
    "ml_client.models.create_or_update(run_model)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc6381e-4b51-4056-8a1c-bb7589a9daee",
   "metadata": {},
   "source": [
    "## View and search for experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57de4b7-74e0-4db3-8781-1b32184d682b",
   "metadata": {},
   "source": [
    "### Search all the active experiments in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75841c7-c2db-4785-bec8-d64494c5f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "experiments = mlflow.search_experiments()\n",
    "for exp in experiments:\n",
    "    print(exp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd4e1ab-1442-4b67-990f-89d26c930aac",
   "metadata": {},
   "source": [
    "To include archived experiments, use `ViewType.ALL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f42d91d-f40d-4778-ad3f-032c29425db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "experiments = mlflow.search_experiments(view_type=ViewType.ALL)\n",
    "for exp in experiments:\n",
    "    print(exp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4729b35-19de-4fe3-8cc4-79fda754d3d1",
   "metadata": {},
   "source": [
    "To retrieve a specific experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3df404-2c51-4fe3-a378-9482e0f089db",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffcbd7-8f47-4f9a-9e5d-596e78e6c78d",
   "metadata": {},
   "source": [
    "### Retrieve runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a91ffb-7325-4851-a36f-512ca9c7e1db",
   "metadata": {},
   "source": [
    "MLflow allows we to search for runs inside of any experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ef8fc-0484-4f72-b5a5-28c47b8658b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(exp.experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66f82b-bd7c-44b3-87c4-e092352c1205",
   "metadata": {},
   "source": [
    "We can use `search_all_experiments=True` if we want to search across all the experiments in the workspace. By default, experiments are ordered descending by `start_time`, which is the time the experiment was queued in Azure Machine Learning. However, we can change this default by using the parameter `order_by`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a8921-d4a2-4cde-8bfc-63c42e46ed3a",
   "metadata": {},
   "source": [
    "For example, if we want to sort by start time and only show the last two results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac93f9-3799-4565-826b-ec10648153b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(exp.experiment_id, order_by=[\"start_time DESC\"], max_results=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5910ff6-7e3e-4537-a312-3879ed1c6072",
   "metadata": {},
   "source": [
    "We can also look for a run with a specific combination in the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75872965-4217-4acc-b6a6-b321ced3b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(\n",
    "    exp.experiment_id, filter_string=\"params.num_boost_round='100'\", max_results=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c615b-5f7b-4f81-befb-f1f3130a2ee1",
   "metadata": {},
   "source": [
    "We can even create a query to filter the runs. Filter query strings are written with a simplified version of the SQL WHERE clause. The code below retrieve runs which train a LogisticRegression model with AUC higher than 0.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b142c-d02a-45ea-9924-4165cccc99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"metrics.AUC > 0.8 and tags.model_type = 'LogisticRegression'\"\n",
    "mlflow.search_runs(exp.experiment_id, filter_string=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b0aad-fc25-4a89-9a2d-44ffb5e1f6e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e2f9d-f550-49ad-8ccd-2ada84b77085",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Run a training script as a command job "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef822ac-d3ef-4d5a-8bd4-39d512ff2ea5",
   "metadata": {},
   "source": [
    "## Create a production-ready script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0f743-f5f2-42ea-922e-48f2c985f728",
   "metadata": {},
   "source": [
    "When we've used notebooks for experimentation and development, we'll first need to convert a notebook to a script. Scripts are ideal for testing and automation in your production environment. To create a production-ready script, we'll need to:\n",
    "\n",
    "- Remove nonessential code\n",
    "- Refactor your code into functions.\n",
    "- Test your script in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0793c0b-5921-4a4b-b683-c1c1d35736ef",
   "metadata": {},
   "source": [
    "### Remove nonessential code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a27d1-adf1-4ae2-a756-7b0431e6c80c",
   "metadata": {},
   "source": [
    "The main benefit of using notebooks is being able to quickly explore your data. For example, we can use `print()` and `df.describe()` statements to explore your data and variables. When we create a script that will be used for automation, we want to avoid including code written for exploratory purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0abdd-dad0-4897-9273-3bb805a08916",
   "metadata": {},
   "source": [
    "### Refactor code into functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc719e8-6dd5-46d2-879b-3197744f122f",
   "metadata": {},
   "source": [
    "Notebook version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f565052-048b-4d2d-bb5a-98623334ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and visualize the data\n",
    "print(\"Reading data...\")\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()\n",
    "\n",
    "# split data\n",
    "print(\"Splitting data...\")\n",
    "X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7507ae5-a94a-48e5-b5c1-9de23806f1b3",
   "metadata": {},
   "source": [
    "Script version (refactored):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e47d03-43cc-4f68-bbf2-d18924d1d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(csv_file):\n",
    "    # read data\n",
    "    df = get_data(csv_file)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c2c5c-02f7-46df-a419-782889068c31",
   "metadata": {},
   "source": [
    "### Test script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea279b3-e87f-4dd7-9c2c-11f5f7995f64",
   "metadata": {},
   "source": [
    "- One simple way to test your script, is to run the script in a terminal. Within the Azure Machine Learning workspace, we can quickly run a script in the terminal of the compute instance.\n",
    "- Alternatively, navigate to Compute > Terminal, and run the code below to run a Python script named `train.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb7a71-9b68-4b1e-a43d-866d22fd3254",
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3590fa-d5dd-49e3-87e1-0d763caec116",
   "metadata": {},
   "source": [
    "## Configure a command job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab023c88-083d-405d-8c40-560bc8294d22",
   "metadata": {},
   "source": [
    "To configure a command job, we'll use the `command` function. To run a script, we'll need to specify values for the following parameters:\n",
    "\n",
    "- `code`: The folder that includes the script to run.\n",
    "- `command`: Specifies which file to run.\n",
    "- `environment`: The necessary packages to be installed on the compute before running the command.\n",
    "- `compute`: The compute to use to run the command.\n",
    "- `display_name`: The name of the individual job.\n",
    "- `experiment_name`: The name of the experiment the job belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9755c1-5560-467b-8dba-039221d82cf2",
   "metadata": {},
   "source": [
    "The code below configure a command job to run a file named `train.py`, on the compute cluster named `aml-cluster` with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afa6c7-8b8a-4cdb-ab31-100c0542a74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"train-model\",\n",
    "    experiment_name=\"train-classification-model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822068fc-f1fe-449d-ad8b-bc683f80eb19",
   "metadata": {},
   "source": [
    "## Submit a command job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb46a1-31cc-4961-9108-8956d83c358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb584d-bf78-41a7-b64e-58325fcbfc58",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfff17-256b-465e-8f85-1de21576e11f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Hyperparameters tuning / Run a sweep job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20717f6-d4ee-4577-ac3c-f0197bfdd9ed",
   "metadata": {},
   "source": [
    "In Azure Machine Learning, we can tune hyperparameters by submitting a script as a **sweep job**. A sweep job will run a **trial** for each hyperparameter combination to be tested. Each trial uses a training script with parameterized hyperparameter values to train a model, and logs the target performance metric achieved by the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4af60a-75f4-4acc-a510-671a326d9a59",
   "metadata": {},
   "source": [
    "## Define a search space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e5a90-f44f-46f7-a556-b429a5e3e635",
   "metadata": {},
   "source": [
    "To define a search space for hyperparameter tuning, create a dictionary with the appropriate parameter expression for each named hyperparameter.\n",
    "\n",
    "For example, the following search space indicates that the `batch_size` hyperparameter can have the value 16, 32, or 64, and the `learning_rate` hyperparameter can have any value from a normal distribution with a mean of 10 and a standard deviation of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d6fa7-e712-42c2-aeb6-789a3e430c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice, Normal\n",
    "\n",
    "command_job_for_sweep = job(\n",
    "    batch_size=Choice(values=[16, 32, 64]), # manually created list    \n",
    "    learning_rate=Normal(mu=10, sigma=3), # distribution list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1aee3f-55d1-421a-92c9-408238f5b7a5",
   "metadata": {},
   "source": [
    "For **discrete** hyperparameters:\n",
    "- `QUniform(min_value, max_value, q)`: Returns a value like round(Uniform(min_value, max_value) / q) * q\n",
    "- `QLogUniform(min_value, max_value, q)`: Returns a value like round(exp(Uniform(min_value, max_value)) / q) * q\n",
    "- `QNormal(mu, sigma, q)`: Returns a value like round(Normal(mu, sigma) / q) * q\n",
    "- `QLogNormal(mu, sigma, q)`: Returns a value like round(exp(Normal(mu, sigma)) / q) * q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed18e2d-7925-4371-9c5a-91c101daaaab",
   "metadata": {},
   "source": [
    "For **continuous** hyperparameters:\n",
    "- `Uniform(min_value, max_value)`: Returns a value uniformly distributed between min_value and max_value\r",
    "- `\n",
    "LogUniform(min_value, max_value`): Returns a value drawn according to exp(Uniform(min_value, max_value)) so that the logarithm of the return value is uniformly distribute\n",
    "- `\r\n",
    "Normal(mu, sigm`a): Returns a real value that's normally distributed with mean mu and standard deviation sig\n",
    "- `a\r\n",
    "LogNormal(mu, sig`ma): Returns a value drawn according to exp(Normal(mu, sigma)) so that the logarithm of the return value is normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e1f158-3fdc-4808-ab07-cfe7758bca24",
   "metadata": {},
   "source": [
    "## Configure a sampling method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e820fe-724e-4318-9e1c-4679909ce628",
   "metadata": {},
   "source": [
    "There are three main sampling methods available in Azure Machine Learning:\n",
    "\n",
    "- Grid sampling: Tries every possible combination.\n",
    "- Random sampling: Randomly chooses values from the search space.\n",
    "    - Sobol: Adds a seed to random sampling to make the results reproducible.\n",
    "- Bayesian sampling: Chooses new values based on previous results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4291b81-806f-4c39-ab0d-5a964593eda1",
   "metadata": {},
   "source": [
    "### Grid sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee28a44-2ff1-4512-b4e0-52a1d955b20f",
   "metadata": {},
   "source": [
    "Grid sampling can only be applied when all hyperparameters are discrete, and is used to try every possible combination of parameters in the search space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e9dd3-c0ae-45bc-b75b-c802540557e3",
   "metadata": {},
   "source": [
    "The example below uses grid sampling to try every possible combination of discrete batch_size and learning_rate value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413dacc2-d17c-4d0a-8bdd-05957e6fe950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice\n",
    "\n",
    "command_job_for_sweep = command_job(\n",
    "    batch_size=Choice(values=[16, 32, 64]),\n",
    "    learning_rate=Choice(values=[0.01, 0.1, 1.0]),\n",
    ")\n",
    "\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    sampling_algorithm = \"grid\",\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b049a1-286d-4ebf-8cdc-5b6dc303d701",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594a004-a677-4f0f-8c81-cdf42bd29b1a",
   "metadata": {},
   "source": [
    "Random sampling is used to randomly select a value for each hyperparameter, which can be a mix of discrete and continuous values as shown in the following code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbb2e1-51b0-4faa-9d10-21c3087dec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Normal, Uniform\n",
    "\n",
    "command_job_for_sweep = command_job(\n",
    "    batch_size=Choice(values=[16, 32, 64]),   \n",
    "    learning_rate=Normal(mu=10, sigma=3),\n",
    ")\n",
    "\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    sampling_algorithm = \"random\",\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52d108-0bf5-439b-b703-1d0d8a32ccbc",
   "metadata": {},
   "source": [
    "#### Sobol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3530a-454d-42c3-974b-b00a768e9d59",
   "metadata": {},
   "source": [
    "To reproduce a random sampling sweep job, we use Sobol instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d96e1a-2aa2-4f64-8436-dabbcaf923b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import RandomSamplingAlgorithm\n",
    "\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    sampling_algorithm = RandomSamplingAlgorithm(seed=123, rule=\"sobol\"),\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e41d20-175d-4cf2-b3c6-b32665bf4fef",
   "metadata": {},
   "source": [
    "### Bayesian sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7cc9a-9071-45d1-8754-5cb0b0ce3d29",
   "metadata": {},
   "source": [
    "Bayesian sampling chooses hyperparameter values based on the Bayesian optimization algorithm, which tries to select parameter combinations that will result in improved performance from the previous selection. The following code example shows how to configure Bayesian sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4706b-e100-4a00-bf4b-9049253bea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Uniform, Choice\n",
    "\n",
    "command_job_for_sweep = job(\n",
    "    batch_size=Choice(values=[16, 32, 64]),    \n",
    "    learning_rate=Uniform(min_value=0.05, max_value=0.1),\n",
    ")\n",
    "\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    sampling_algorithm = \"bayesian\",\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af37b86-3f12-44d7-803f-a5f99fe8be28",
   "metadata": {},
   "source": [
    "## Configure early termination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c97ec-324d-4cb1-95b4-52f371a830af",
   "metadata": {},
   "source": [
    "When we configure a sweep job in Azure Machine Learning, we can also set a maximum number of trials. A more sophisticated approach may be to stop a sweep job when newer models **don't produce significantly better results**. To stop a sweep job based on the performance of the models, we can use an **early termination policy**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c09051-9277-4a78-88bf-8753a0bcb8bc",
   "metadata": {},
   "source": [
    "We'll most likely want to use an early termination policy when working with **continuous hyperparameters** and a **random** or **Bayesian sampling** method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69678524-f143-41a7-92e5-5d7ff0ff9fa6",
   "metadata": {},
   "source": [
    "There are two main parameters when we choose to use an early termination policy:\n",
    "- `evaluation_interval`: Specifies at which interval we want the policy to be evaluated. Every time the primary metric is logged for a trial counts as an interval.\r",
    "- `\n",
    "delay_evaluatio`n: Specifies when to start evaluating the policy. This parameter allows for at least a minimum of trials to complete without an early termination policy affecting them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b28b8-4312-49bf-825b-014ac8d920b2",
   "metadata": {},
   "source": [
    "There are three options to determine the extent to which a model should perform better than previous trials:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a9232-056d-4226-93bb-38eab96a91ab",
   "metadata": {},
   "source": [
    "### Option 1: Bandit policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a111431-fea9-4796-a9f8-e7f060588d24",
   "metadata": {},
   "source": [
    "Bandit policy: Uses a `slack_factor` (relative) or `slack_amount`(absolute). Any new model must perform within the slack range of the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad46d3-6715-4a08-82a9-0f43e2341fdb",
   "metadata": {},
   "source": [
    "For example, the following code applies a bandit policy with a delay of five trials, evaluates the policy at every interval, and allows an absolute slack amount of 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e58f3a-b03f-4f48-8a52-a1a6dbacaf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import BanditPolicy\n",
    "\n",
    "sweep_job.early_termination = BanditPolicy(\n",
    "    slack_amount = 0.2, \n",
    "    delay_evaluation = 5, \n",
    "    evaluation_interval = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367fe26d-3add-4a33-8ddf-8ce651f051a6",
   "metadata": {},
   "source": [
    "### Option 2: Median stopping policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7fb6ab-5a39-4d3f-8509-691b51cd6cd5",
   "metadata": {},
   "source": [
    "Median stopping policy: Uses the median of the averages of the primary metric. Any new model must perform better than the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf41ec-82c4-4593-8460-78204b761c7a",
   "metadata": {},
   "source": [
    "For example, the following code applies a median stopping policy with a delay of five trials and evaluates the policy at every interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0ff14-5013-4b84-985b-4811512a0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import MedianStoppingPolicy\n",
    "\n",
    "sweep_job.early_termination = MedianStoppingPolicy(\n",
    "    delay_evaluation = 5, \n",
    "    evaluation_interval = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9268b4c8-c8dc-4c95-a279-392c0a7ed5cd",
   "metadata": {},
   "source": [
    "### Option 3: Truncation selection policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5dd84c-9d45-4026-8053-13d4fd63db63",
   "metadata": {},
   "source": [
    "Truncation selection policy: Uses a `truncation_percentage`, which is the percentage of lowest performing trials. Any new model must perform better than the lowest performing trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b68655-05e0-4687-b4c9-6470f65e3d23",
   "metadata": {},
   "source": [
    "For example, the following code applies a truncation selection policy with a delay of four trials, evaluates the policy at every interval, and uses a truncation percentage of 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f0fcf-3f35-4eee-a19b-cff9baba2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import TruncationSelectionPolicy\n",
    "\n",
    "sweep_job.early_termination = TruncationSelectionPolicy(\n",
    "    evaluation_interval=1, \n",
    "    truncation_percentage=20, \n",
    "    delay_evaluation=4 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11c05e-934e-498f-9d12-132fb52672ed",
   "metadata": {},
   "source": [
    "## Use a sweep job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f865ca-06e9-4d56-9357-2194d7cc6327",
   "metadata": {},
   "source": [
    "### Step 1: Create a training script for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366d1fe8-6940-461d-9213-56a0681f01dc",
   "metadata": {},
   "source": [
    "To run a sweep job, we need to create a training script just the way we would do for any other training job, except that your script must:\n",
    "- Include an argument for each hyperparameter we want to vary.\n",
    "- Log the target performance metric with MLflow. A logged metric enables the sweep job to evaluate the performance of the trials it initiates, and identify the one that produces the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d1b40-8f1f-40a9-ab4d-1099fe8d4ca1",
   "metadata": {},
   "source": [
    "For example, the following example script trains a logistic regression model using a `--regularization` argument to set the regularization rate hyperparameter, and logs the accuracy metric with the name `Accuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ee56f-4075-44d4-b079-16e849f59986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow\n",
    "\n",
    "# get regularization hyperparameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# load the training dataset\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# separate features and labels, and split for training/validatiom\n",
    "X = data[['feature1','feature2','feature3','feature4']].values\n",
    "y = data['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "# train a logistic regression model with the reg hyperparameter\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate and log accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "mlflow.log_metric(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d169e8bb-9e0b-4be0-aabb-bec35c1f2883",
   "metadata": {},
   "source": [
    "### Step 2: Create a base command job that specifies script and define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9d377-3135-4ca7-82fb-1c728cf668db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure command job as base\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train.py --regularization ${{inputs.reg_rate}}\",\n",
    "    inputs={\n",
    "        \"reg_rate\": 0.01,\n",
    "    },\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d68896-4501-4411-9ef1-c4ea466a7536",
   "metadata": {},
   "source": [
    "### Step 3: Override the input parameters with the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10321970-6a77-404d-9fad-2fa2d3be166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice\n",
    "\n",
    "command_job_for_sweep = job(\n",
    "    reg_rate=Choice(values=[0.01, 0.1, 1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbed1a9-2c62-4a60-887c-7d80c615b9c4",
   "metadata": {},
   "source": [
    "### Step 4: Configure and submit the sweep job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b2444-f4ed-4772-853c-b744d67cabb5",
   "metadata": {},
   "source": [
    "To configure the sweep jobs:\n",
    "- `compute`: Name of the compute target to execute the job on.\n",
    "- `sampling_algorithm`: The hyperparameter sampling algorithm to use over the search space. Allowed values are `random`, `grid` and `bayesian`.\n",
    "- `primary_metric`: The name of the primary metric reported by each trial job. The metric must be logged in the user's training script using `mlflow.log_metric()` with the same corresponding metric name.\n",
    "- `goal`: The optimization goal of the primary_metric. The allowed values are `maximize` and `minimize`.\n",
    "- `limits`: Limits for the sweep job. For example, the maximum amount of trials or models we want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ba11a-7863-4d99-bbd3-35168ab6f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# apply the sweep parameter to obtain the sweep_job\n",
    "sweep_job = command_job_for_sweep.sweep(\n",
    "    compute=\"aml-cluster\",\n",
    "    sampling_algorithm=\"grid\",\n",
    "    primary_metric=\"Accuracy\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "\n",
    "# set the name of the sweep job experiment\n",
    "sweep_job.experiment_name=\"sweep-example\"\n",
    "\n",
    "# define the limits for this sweep\n",
    "sweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)\n",
    "\n",
    "# submit the sweep\n",
    "returned_sweep_job = ml_client.create_or_update(sweep_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea2ce1-3748-4e3a-82ee-635cec07a511",
   "metadata": {},
   "source": [
    "### Step 5: Motitor a sweep job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54809c68-4e02-4198-8e04-f8f28fef146f",
   "metadata": {},
   "source": [
    "We can monitor sweep jobs in Azure Machine Learning studio. The sweep job will initiate trials for each hyperparameter combination to be tried. For each trial, we can review all logged metrics. The code below gives the direct link to monitor the sweep job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e1270-5cff-4f42-ab4a-a1bfe7d961f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_url = returned_sweep_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e16566-8e76-498e-8ff1-b7e1de360588",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8deed-a8b6-4b10-bc84-ee1857ea6559",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3d5fd-c6cf-4ec2-ac21-f56aa6edf26c",
   "metadata": {},
   "source": [
    "**Definition**: In Azure Machine Learning, a pipeline is a workflow of machine learning tasks in which each task is defined as a component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b49e2-f314-4513-a775-0c549f04fc49",
   "metadata": {},
   "source": [
    "## Component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b659e169-96a9-4de3-81e9-e8751a4689b2",
   "metadata": {},
   "source": [
    "Components allow we to create reusable scripts that can easily be shared across users within the same Azure Machine Learning workspace. It's an effective way to build an Azure ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abec85d-048c-4394-9a42-fde2ecd47c81",
   "metadata": {},
   "source": [
    "A component consists of three parts:\n",
    "- **Metadata**: Includes the component's name, version, etc.\n",
    "- **Interface**: Includes the expected input parameters (like a dataset or hyperparameter) and expected output (like metrics and artifacts).\n",
    "- **Command**, **code** and **environment**: Specifies how to run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7612e6b-d858-4e66-9ec1-709e80eac4ef",
   "metadata": {},
   "source": [
    "To create a component, we need two files:\n",
    "- A **script** that contains the workflow we want to execute.\n",
    "- A **YAML** file to define the metadata, interface, and command, code, and environment of the component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab2db5-c5fa-4a84-b0c3-169b5d3179b6",
   "metadata": {},
   "source": [
    "For example, let's say we have a Python script `prep.py` that preparares the data by removing missing values and normalizing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c3319-ee15-4c87-8122-a140b8417edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# setup arg parser\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# add arguments\n",
    "parser.add_argument(\"--input_data\", dest='input_data',\n",
    "                    type=str)\n",
    "parser.add_argument(\"--output_data\", dest='output_data',\n",
    "                    type=str)\n",
    "\n",
    "# parse args\n",
    "args = parser.parse_args()\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(args.input_data)\n",
    "\n",
    "# remove missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# normalize the data    \n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['feature1','feature2','feature3','feature4']\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# save the data as a csv\n",
    "output_df = df.to_csv(\n",
    "    (Path(args.output_data) / \"prepped-data.csv\"), \n",
    "    index = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d9512-c761-4b67-a9e0-1ca3e2ff2a92",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43809fe2-dd2e-42f2-b474-fd09ace5296e",
   "metadata": {},
   "source": [
    "To create a component for the `prep.py` script, we'll need a YAML file `prep.yml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965a533-fb54-4066-ad01-fbd9be61126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a yml code, not Python\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\n",
    "name: prep_data\n",
    "display_name: Prepare training data\n",
    "version: 1\n",
    "type: command\n",
    "inputs:\n",
    "  input_data: \n",
    "    type: uri_file\n",
    "outputs:\n",
    "  output_data:\n",
    "    type: uri_file\n",
    "code: ./src\n",
    "environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\n",
    "command: >-\n",
    "  python prep.py \n",
    "  --input_data ${{inputs.input_data}}\n",
    "  --output_data ${{outputs.output_data}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c06943-644f-4213-9ba0-7adfb5f8a49d",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d7caa-ea40-47bf-851d-c764e893844e",
   "metadata": {},
   "source": [
    "Now we can load the component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f28a8ba-7efc-4dbc-9b6c-e029830aea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_component\n",
    "parent_dir = \"\"\n",
    "\n",
    "loaded_component_prep = load_component(source=parent_dir + \"./prep.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedef8f-1cef-404c-97eb-5550fe0ce142",
   "metadata": {},
   "source": [
    "### Register"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a5490-f9fb-48fa-8e3e-ee6d9b49d73c",
   "metadata": {},
   "source": [
    "Finally, to make the components accessible to other users in the workspace, we can also register components to the Azure Machine Learning workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db64f97-fa95-46f1-b651-47c7c4b1f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = ml_client.components.create_or_update(prepare_data_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1da11f-13d6-4f4a-9a4a-bf2a834fe017",
   "metadata": {},
   "source": [
    "## Create a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58915e8-d503-4ec1-8739-3f4c9f81beba",
   "metadata": {},
   "source": [
    "An Azure Machine Learning pipeline is defined in a YAML file. The YAML file includes the pipeline job name, inputs, outputs, and settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cdf395-1f9b-4137-8bee-f5446ac495dd",
   "metadata": {},
   "source": [
    "For example, if we want to build a pipeline that first prepares the data, and then trains the model, the step by step explaination should be:\n",
    "1. The pipeline is built by defining the function `pipeline_function_name`.\n",
    "2. The pipeline function expects `pipeline_job_input` as the overall pipeline input.\n",
    "3. The first pipeline step requires a value for the input parameter `input_data`. The value for the input will be the value of `pipeline_job_input`.\n",
    "4. The first pipeline step is defined by the loaded component for `prep_data`.\n",
    "5. The value of the `output_data` of the first pipeline step is used for the expected input `training_data` of the second pipeline step.\n",
    "6. The second pipeline step is defined by the loaded component for `train_model` and results in a trained model referred to by `model_output`.\n",
    "7. Pipeline outputs are defined by returning variables from the pipeline function. There are two outputs:\n",
    "    - `pipeline_job_transformed_data` with the value of `prep_data.outputs.output_data`\n",
    "    - `pipeline_job_trained_model` with the value of `train_model.outputs.model_output`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4631af0-1bc8-469c-9cd4-7a540957cd95",
   "metadata": {},
   "source": [
    "We can achieve this pipeline by using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2d47c-51de-485d-9b19-ded808d02071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "\n",
    "@pipeline()\n",
    "def pipeline_function_name(pipeline_job_input):\n",
    "    prep_data = loaded_component_prep(input_data=pipeline_job_input)\n",
    "    train_model = loaded_component_train(training_data=prep_data.outputs.output_data)\n",
    "\n",
    "    return {\n",
    "        \"pipeline_job_transformed_data\": prep_data.outputs.output_data,\n",
    "        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08933876-93fc-4dd5-9649-1cda0c9efc47",
   "metadata": {},
   "source": [
    "To pass a registered data asset as the pipeline job input, we can call the function we created with the data asset as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50ca8e-96a2-4b41-a374-21fe0ee2816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "pipeline_job = pipeline_function_name(\n",
    "    Input(type=AssetTypes.URI_FILE, \n",
    "    path=\"azureml:data:1\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5d105a-58d7-4184-b0ff-7c33492e497e",
   "metadata": {},
   "source": [
    "The result then can be reviewed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b2de4-16b6-4121-89c6-18f1fb4d3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b1675-16c7-4d1f-89b1-dd0e2c4471a4",
   "metadata": {},
   "source": [
    "We can also change any parameter of the pipeline job configuration by referring to the parameter and specifying the new value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff849b70-170a-4450-a625-d073e2ad1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the output mode\n",
    "pipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\n",
    "pipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"\n",
    "# set pipeline level compute\n",
    "pipeline_job.settings.default_compute = \"aml-cluster\"\n",
    "# set pipeline level datastore\n",
    "pipeline_job.settings.default_datastore = \"workspaceblobstore\"\n",
    "\n",
    "# print the pipeline job again to review the changes\n",
    "print(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa75a4d7-00c1-47d0-8f57-b1cf0d1af41a",
   "metadata": {},
   "source": [
    "## Run a pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8478f-87c0-48f9-8e03-451bf97b59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit job to workspace\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"pipeline_job\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3260aa5e-7b3b-4f91-9747-1141ecbcc487",
   "metadata": {},
   "source": [
    "## Schedule a pipeline job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ccdb-f534-4ed0-897a-e6c0ffeed06a",
   "metadata": {},
   "source": [
    "A pipeline is ideal if we want to get your model ready for production. Pipelines are especially useful for automating the retraining of a machine learning model. To automate the retraining of a model, we can schedule a pipeline.\n",
    "\n",
    "To schedule a pipeline job, we'll use the `JobSchedule` class to associate a schedule to a pipeline job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c162d1-270b-4a25-a304-130cab2efc3e",
   "metadata": {},
   "source": [
    "### Step 1: Create a schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d12e1-94a0-4784-b817-8eae8176c388",
   "metadata": {},
   "source": [
    "There are various ways to create a schedule. A simple approach is to create a time-based schedule using the `RecurrenceTrigger` class with the following parameters:\n",
    "\n",
    "- `frequency`: Unit of time to describe how often the schedule fires. Value can be either minute, hour, day, week, or month.\n",
    "- `interval`: Number of frequency units to describe how often the schedule fires. Value needs to be an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cc13f4-fa47-434d-89ce-92b1c8cc57b6",
   "metadata": {},
   "source": [
    "The code below create a schedule that fires every minute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ffa7d-fe18-4843-b355-51f4ea451177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import RecurrenceTrigger\n",
    "\n",
    "schedule_name = \"run_every_minute\"\n",
    "\n",
    "recurrence_trigger = RecurrenceTrigger(\n",
    "    frequency=\"minute\",\n",
    "    interval=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a1a4b-333e-44c8-bed0-aed0fb46d544",
   "metadata": {},
   "source": [
    "### Step 2: Schedule a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e2518-4cd1-4b2e-ab4a-ba823470364c",
   "metadata": {},
   "source": [
    "To schedule a pipeline, we'll need `pipeline_job` to represent the pipeline we've built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258c327-9685-4338-b2b6-4b8684f47fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import JobSchedule\n",
    "\n",
    "job_schedule = JobSchedule(\n",
    "    name=schedule_name, trigger=recurrence_trigger, create_job=pipeline_job\n",
    ")\n",
    "\n",
    "job_schedule = ml_client.schedules.begin_create_or_update(\n",
    "    schedule=job_schedule\n",
    ").result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7546287a-06f6-474c-b74d-216c721c2c09",
   "metadata": {},
   "source": [
    "### Delete a schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53017be0-35d9-4ace-975f-44fec98b9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "To delete a schedule, we first need to disable it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe46291-1609-4c1b-a576-cea3315fd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.schedules.begin_disable(name=schedule_name).result()\n",
    "ml_client.schedules.begin_delete(name=schedule_name).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04e479-7dc4-4478-b411-079fef81d664",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30d9a7-5a1f-407f-b4dc-f650ce9894eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Responsible AI (RAI) dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983ae26-bbe9-4f76-badf-1550bc866572",
   "metadata": {},
   "source": [
    "When we compare and evaluate your machine learning models, we'll want to review more than just their performance metric. Azure Machine Learning allows we to create responsible AI dashboard to explore how the model performs on different cohorts of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769e0ac-61bb-431b-8175-ae8885ea9722",
   "metadata": {},
   "source": [
    "## Step 1: Create the data asssets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a9b78-7387-4cf4-8f16-9afe18628593",
   "metadata": {},
   "source": [
    "To create the responsible AI dashboard, we need to register the training and testing datasets as MLtable data assets. The MLtable data assets reference the Parquet files we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad591c7-6788-4d9f-9418-365c2e2c04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"train-data/\"\n",
    "test_data_path = \"test-data/\"\n",
    "data_version = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad60d2-7707-4d03-8a6e-d29efbdc3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "input_train_data = \"diabetes_train_mltable\"\n",
    "input_test_data = \"diabetes_test_mltable\"\n",
    "\n",
    "try:\n",
    "    # Try getting data already registered in workspace\n",
    "    train_data = ml_client.data.get(\n",
    "        name=input_train_data,\n",
    "        version=data_version,\n",
    "    )\n",
    "    test_data = ml_client.data.get(\n",
    "        name=input_test_data,\n",
    "        version=data_version,\n",
    "    )\n",
    "except Exception as e:\n",
    "    train_data = Data(\n",
    "        path=train_data_path,\n",
    "        type=AssetTypes.MLTABLE,\n",
    "        description=\"RAI diabetes training data\",\n",
    "        name=input_train_data,\n",
    "        version=data_version,\n",
    "    )\n",
    "    ml_client.data.create_or_update(train_data)\n",
    "\n",
    "    test_data = Data(\n",
    "        path=test_data_path,\n",
    "        type=AssetTypes.MLTABLE,\n",
    "        description=\"RAI diabetes test data\",\n",
    "        name=input_test_data,\n",
    "        version=data_version,\n",
    "    )\n",
    "    ml_client.data.create_or_update(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe716a08-5aea-430c-9645-2a0abb1c389b",
   "metadata": {},
   "source": [
    "## Step 2: Build the pipeline to create the responsible AI dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a01a2b0-3814-44d4-ad73-989b954d81c8",
   "metadata": {},
   "source": [
    "### Step 2.1: Get Azure ML registry for RAI components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496f021-5797-426d-a284-f1f224f04af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get handle to azureml registry for the RAI built in components\n",
    "registry_name = \"azureml\"\n",
    "ml_client_registry = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=ml_client.subscription_id,\n",
    "    resource_group_name=ml_client.resource_group_name,\n",
    "    registry_name=registry_name,\n",
    ")\n",
    "print(ml_client_registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b8f58-eee3-409b-90cc-6e6622e7015c",
   "metadata": {},
   "source": [
    "### Step 2.2: Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321c6c6-716a-4e26-a7aa-ef861519534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "file_model = Model(\n",
    "    path=\"model\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    name=\"local-mlflow-diabetes\",\n",
    "    description=\"Model created from local file.\",\n",
    ")\n",
    "model = ml_client.models.create_or_update(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f3a4aa-04fa-40c5-abde-85484f99ddeb",
   "metadata": {},
   "source": [
    "### Step 2.3: Setting up RAI pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836065d-60bb-4069-b181-2a7a09f4d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model.name\n",
    "expected_model_id = f\"{model_name}:1\"\n",
    "azureml_model_id = f\"azureml:{expected_model_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a089470-488d-4e94-b014-9ce8aa8886bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"latest\"\n",
    "\n",
    "# Start with RAI Insights dashboard constructor component:\n",
    "rai_constructor_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\n",
    ")\n",
    "\n",
    "# we get latest version and use the same version for all components\n",
    "version = rai_constructor_component.version\n",
    "print(\"The current version of RAI built-in components is: \" + version)\n",
    "\n",
    "# Add Error Analysis to RAI Insights dashboard component\n",
    "rai_erroranalysis_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\n",
    ")\n",
    "\n",
    "# Add Explanation to RAI Insights dashboard component\n",
    "rai_explanation_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\n",
    ")\n",
    "\n",
    "# End with a Gather RAI Insights dashboard component\n",
    "rai_gather_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5159f-f053-45af-9b76-ad69b0160df6",
   "metadata": {},
   "source": [
    "### Step 2.4: Setting up the semi-complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb77d87-e0e4-48f9-a040-c34012d9d39f",
   "metadata": {},
   "source": [
    "Finally, we build the pipeline and connect the components in the appropriate order:\n",
    "1. Construct the dashboard.\n",
    "2. Add error analysis.\n",
    "3. Add explanations.\n",
    "4. Gather all insights and visualize them in the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4ef453-5e6a-4aed-ac90-4ac8d18b19d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input, dsl\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "compute_name = \"aml-cluster\"\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=compute_name,\n",
    "    description=\"RAI insights on diabetes data\",\n",
    "    experiment_name=f\"RAI_insights_{model_name}\",\n",
    ")\n",
    "def rai_decision_pipeline(\n",
    "    target_column_name, train_data, test_data\n",
    "):\n",
    "    # Initiate the RAIInsights\n",
    "    create_rai_job = rai_constructor_component(\n",
    "        title=\"RAI dashboard diabetes\",\n",
    "        task_type=\"classification\",\n",
    "        model_info=expected_model_id,\n",
    "        model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n",
    "        train_dataset=train_data,\n",
    "        test_dataset=test_data,\n",
    "        target_column_name=target_column_name,\n",
    "    )\n",
    "    create_rai_job.set_limits(timeout=300)\n",
    "\n",
    "    # Add error analysis\n",
    "    error_job = rai_erroranalysis_component(\n",
    "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "    )\n",
    "    error_job.set_limits(timeout=300)\n",
    "\n",
    "    # Add explanations\n",
    "    explanation_job = rai_explanation_component(\n",
    "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "        comment=\"add explanation\", \n",
    "    )\n",
    "    explanation_job.set_limits(timeout=300)\n",
    "\n",
    "    # Combine everything\n",
    "    rai_gather_job = rai_gather_component(\n",
    "        constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
    "        insight_3=error_job.outputs.error_analysis,\n",
    "        insight_4=explanation_job.outputs.explanation,\n",
    "    )\n",
    "    rai_gather_job.set_limits(timeout=300)\n",
    "\n",
    "    rai_gather_job.outputs.dashboard.mode = \"upload\"\n",
    "\n",
    "    return {\n",
    "        \"dashboard\": rai_gather_job.outputs.dashboard,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c895867-f30d-42d7-baab-54267aec6c8e",
   "metadata": {},
   "source": [
    "### Step 2.5: Define inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b32053-5401-4ed4-ad00-3cd6f1ec02fb",
   "metadata": {},
   "source": [
    "Now the pipeline has been built, we need to define the two necessary inputs: the training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31061f6e-e1f8-4dd2-aa90-e4c1daad0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "target_feature = \"Diabetic\"\n",
    "\n",
    "diabetes_train_pq = Input(\n",
    "    type=\"mltable\",\n",
    "    path=f\"azureml:{input_train_data}:{data_version}\",\n",
    "    mode=\"download\",\n",
    ")\n",
    "diabetes_test_pq = Input(\n",
    "    type=\"mltable\",\n",
    "    path=f\"azureml:{input_test_data}:{data_version}\",\n",
    "    mode=\"download\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419c6de-b3d2-4ccd-b4dd-6ee341eab030",
   "metadata": {},
   "source": [
    "### Step 2.6: Setting up complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400f9fd-ba9e-45aa-b148-482ad188af6a",
   "metadata": {},
   "source": [
    "Finally, we'll put everything together: assign the inputs to the pipeline and set the target column (the predicted label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb38548-e0ca-40b9-9bfd-741999706870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from azure.ai.ml import Output\n",
    "\n",
    "# Pipeline to construct the RAI Insights\n",
    "insights_pipeline_job = rai_decision_pipeline(\n",
    "    target_column_name=\"Diabetic\",\n",
    "    train_data=diabetes_train_pq,\n",
    "    test_data=diabetes_test_pq,\n",
    ")\n",
    "\n",
    "# Workaround to enable the download\n",
    "rand_path = str(uuid.uuid4())\n",
    "insights_pipeline_job.outputs.dashboard = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c185ec-d549-4d86-81bb-e39d8ffdc50b",
   "metadata": {},
   "source": [
    "## Step 3: Run the complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2633360-338b-4057-8922-78ad97623595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import PipelineJob\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
    "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    assert created_job is not None\n",
    "\n",
    "    print(\"Pipeline job can be accessed in the following URL:\")\n",
    "    display(HTML('{0}'.format(created_job.studio_url)))\n",
    "\n",
    "    while created_job.status not in [\n",
    "        \"Completed\",\n",
    "        \"Failed\",\n",
    "        \"Canceled\",\n",
    "        \"NotResponding\",\n",
    "    ]:\n",
    "        time.sleep(30)\n",
    "        created_job = ml_client.jobs.get(created_job.name)\n",
    "        print(\"Latest status : {0}\".format(created_job.status))\n",
    "    assert created_job.status == \"Completed\"\n",
    "    return created_job\n",
    "\n",
    "\n",
    "# This is the actual submission\n",
    "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edf938-cc65-454a-b801-01fbc7f64b79",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fa6e50-8e6c-4915-ab6e-46ecd68f120e",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6971b-bee5-460a-930f-c10cbce04b5d",
   "metadata": {},
   "source": [
    "## Deploy a model to a managed online endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25632014-2111-4cf5-9808-b86916ee34d5",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577da6a2-a2ab-41ed-869c-ccfc4b193a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=\"endpoint-example\",\n",
    "    description=\"Online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "\n",
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981a551-ef36-494a-97e6-ff76b07c3bf2",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc57df-08d5-4071-b3a6-17867677496c",
   "metadata": {},
   "source": [
    "#### Option 1: MLmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ad147-64a8-411d-becd-428fa1d39f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# create a blue deployment\n",
    "model = Model(\n",
    "    path=\"./model\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    description=\"my sample mlflow model\",\n",
    ")\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=\"endpoint-example\",\n",
    "    model=model,\n",
    "    instance_type=\"Standard_F4s_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf868d-7666-4acf-8be6-10d116048ce0",
   "metadata": {},
   "source": [
    "##### Route traffic to a specific deployment, use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479f3da-06a8-4201-9611-ad435152ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224e62d-880b-4589-a6b2-7189aa43f467",
   "metadata": {},
   "source": [
    "#### Option 2: Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697192b-033e-442a-b200-bdff711b048a",
   "metadata": {},
   "source": [
    "For a custom model, additional requirements must be met:\n",
    "- Model files stored on local path or registered model.\n",
    "- A scoring script (details below)\n",
    "- An execution environment. (to create an environment, check the Environtment - section5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf69efe-9aa3-4d57-9531-a85a8167c6ea",
   "metadata": {},
   "source": [
    "To deploy a model to an endpoint, we can specify the compute configuration with two parameters:\n",
    "- `instance_type`: Virtual machine (VM) size to use. Review the list of supported sizes.\n",
    "- `instance_count`: Number of instances to use.\n",
    "\n",
    "To deploy the model, use the `ManagedOnlineDeployment` class and run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2b61e-3681-4bb4-992e-7d6efe1612ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n",
    "\n",
    "model = Model(path=\"./model\",\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=\"endpoint-example\",\n",
    "    model=model,\n",
    "    environment=\"deployment-environment\",\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./src\", scoring_script=\"score.py\"\n",
    "    ),\n",
    "    instance_type=\"Standard_DS2_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3065ca4e-3c7d-4ade-963f-f4323fb25062",
   "metadata": {},
   "source": [
    "#### Scoring script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163c1a98-86e8-41af-83f1-910fb1088d8b",
   "metadata": {},
   "source": [
    "The scoring script needs to include two functions:\n",
    "- `init()`: called when the deployment is created or updated, to load and cache the model from the model registry.\n",
    "- `run()`: called for every time the endpoint is invoked, to generate predictions from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba69110-5270-4f25-84e2-08b31fb3ab57",
   "metadata": {},
   "source": [
    "Below is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e308e36-c50d-4bea-9e7c-281e6995d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# called when the deployment is created or updated\n",
    "def init():\n",
    "    global model\n",
    "    # get the path to the registered model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# called when a request is received\n",
    "def run(raw_data):\n",
    "    # get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # return the predictions as any JSON serializable format\n",
    "    return predictions.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b382a-e935-4a5a-baf0-dea427861dcc",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b1ea9-e346-40b4-9cde-f64c1e0456ac",
   "metadata": {},
   "source": [
    "Typically, we send data to deployed model in JSON format with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecd765-a8f9-4180-9fe4-feeaaa59472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is JSON code, not Python\n",
    "{\n",
    "  \"data\":[\n",
    "      [0.1,2.3,4.1,2.0], // 1st case\n",
    "      [0.2,1.8,3.9,2.1],  // 2nd case,\n",
    "      ...\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d40b0-f99f-42df-bd4c-1d8f6c45547f",
   "metadata": {},
   "source": [
    "The response from the deployed model is a JSON collection with a prediction for each case that was submitted in the data. The following code sample invokes an endpoint and displays the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1870b16-ab81-438c-b7fa-f078593e405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the blue deployment with some sample data\n",
    "response = ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"blue\",\n",
    "    request_file=\"sample-data.json\",\n",
    ")\n",
    "\n",
    "if response[1]=='1':\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print (\"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0932a3-cbfd-4812-b6da-224be82a7c44",
   "metadata": {},
   "source": [
    "### View endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69240725-2797-4283-9b0a-2db11c8ac547",
   "metadata": {},
   "source": [
    "To list all endpoints, use `online_endpoints.list()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf128c83-bf73-4e53-9e11-2eea1cce97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = ml_client.online_endpoints.list()\n",
    "for endp in endpoints:\n",
    "    print(endp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c6bf4-43f7-484b-976a-a6477eda58d6",
   "metadata": {},
   "source": [
    "To get endpoint's details, use `online_endpoints.get()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57666a5d-78f5-4942-adc9-3ddecc903ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309ce82-d019-4542-8611-e4f90363ed78",
   "metadata": {},
   "source": [
    "### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ebd82-23e8-4d87-8ec3-e97a665d84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(name=\"endpoint-example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae584a5f-978a-45fa-810f-5e273b02fd85",
   "metadata": {},
   "source": [
    "## Deploy a model to a managed online endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e8ac6-6145-41e1-a7d3-6feaafec2823",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0321c1-6a37-4e0f-839d-8b7e042e96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a batch endpoint\n",
    "endpoint = BatchEndpoint(\n",
    "    name=\"endpoint-example\",\n",
    "    description=\"A batch endpoint\",\n",
    ")\n",
    "\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3be62-5562-4d1e-adfb-4528c9081a4d",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f48585-03bf-496e-81b9-2cb7b912d9d4",
   "metadata": {},
   "source": [
    "#### Option 1: MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d42b5-3266-4952-b460-af7a7c3bd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the model\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "model_name = 'mlflow-model'\n",
    "model = ml_client.models.create_or_update(\n",
    "    Model(name=model_name, path='./model', type=AssetTypes.MLFLOW_MODEL)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0bb8c7-b17b-4de3-ae16-95ea7a149854",
   "metadata": {},
   "source": [
    "To deploy an MLflow model to a batch endpoint, we'll use the `BatchDeployment` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366439b4-9245-48b2-80fa-4ec502a985b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "\n",
    "deployment = BatchDeployment(\n",
    "    name=\"classifier-diabetes-mlflow\",\n",
    "    description=\"A diabetes classifier\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model,\n",
    "    compute=\"aml-cluster\",\n",
    "    instance_count=2,\n",
    "    max_concurrency_per_instance=2,\n",
    "    mini_batch_size=2,\n",
    "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "    output_file_name=\"predictions.csv\",\n",
    "    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "    logging_level=\"info\",\n",
    ")\n",
    "ml_client.batch_deployments.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d84a5-8f5e-42eb-ba74-6b85d9aaec18",
   "metadata": {},
   "source": [
    "We deployed for example a model with the following parameters:\n",
    "\n",
    "- `name`: Name of the deployment.\n",
    "- `description`: Optional description to further clarify what the deployment represents.\n",
    "- `endpoint_name`: Name of the previously created endpoint the model should be deployed to.\n",
    "- `model`: Name of the registered model.\n",
    "- `compute`: Compute to be used when invoking the deployed model to generate predictions.\n",
    "- `instance_count`: Count of compute nodes to use for generating predictions.\n",
    "- `max_concurrency_per_instance`: Maximum number of parallel scoring script runs per compute node.\n",
    "- `mini_batch_size`: Number of files passed per scoring script run.\n",
    "- `output_action`: Each new prediction will be appended as a new row to the output file.\n",
    "- `output_file_name`: File to which predictions will be appended.\n",
    "- `retry_settings`: Settings for a mini-batch fails.\n",
    "- `logging_level`: The log verbosity level. Allowed values are warning, info, and debug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c704c-d79c-486c-9cfd-be17e96e9179",
   "metadata": {},
   "source": [
    "#### Option 2: Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e037a-7ebe-4795-8c04-f57565eb31ce",
   "metadata": {},
   "source": [
    "The requirements for a custom model running batch predictions are the same as those for online endpoint deployment. The code below demonstrates an example configuration and creation of a deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cfc24e-6ea5-4959-b051-fa00910a6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "\n",
    "deployment = BatchDeployment(\n",
    "    name=\"classifier-diabetes-mlflow\",\n",
    "    description=\"A diabetes classifier\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model,\n",
    "    compute=\"aml-cluster\",\n",
    "    instance_count=2,\n",
    "    max_concurrency_per_instance=2,\n",
    "    mini_batch_size=2,\n",
    "    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "    output_file_name=\"predictions.csv\",\n",
    "    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "    logging_level=\"info\",\n",
    ")\n",
    "ml_client.batch_deployments.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9990a47e-ffe7-4f9f-ade1-27e3597b271f",
   "metadata": {},
   "source": [
    "### Submit the job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c7885a-69bc-434e-acdd-06ea3df8da02",
   "metadata": {},
   "source": [
    "Now that we have deployed a model to a batch endpoint, we're ready to invoke the endpoint to generate predictions on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4687b40-7dd3-4743-94c9-6dc38d7014e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input by referring to the registered data asset\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "input = Input(type=AssetTypes.URI_FOLDER, path=patient_dataset_unlabeled.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062465c8-8b8c-42e8-855c-cfbf83abd6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the endpoint, which will submit a pipeline job\n",
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint.name, \n",
    "    input=input)\n",
    "\n",
    "ml_client.jobs.get(job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418773c-21cc-4ebe-b255-84b9c10d7c9d",
   "metadata": {},
   "source": [
    "### Get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092aa8a-60f3-4bdb-9e18-1bd3c4379bfa",
   "metadata": {},
   "source": [
    "When the pipeline job that invokes the batch endpoint is completed, we can view the results. All predictions are collected in the `predictions.csv` file that is stored in the default datastore. we can download the file and visualize the data by running the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768a979-a30e-4fd4-bbb5-2dcfefa67ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client.jobs.download(name=job.name, download_path=\".\", output_name=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af3d56-a99e-4667-a59e-4e9e4c235004",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions.csv\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96666a3-8b6a-4379-9ee9-5cc7a7dc7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "\n",
    "score = pd.DataFrame(\n",
    "    literal_eval(data.replace(\"\\n\", \",\")), columns=[\"file\", \"prediction\"]\n",
    ")\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415728a8-325f-4813-aa4c-1670fceca075",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family:'Glacial Indifference', sans-serif; font-size:32px; text-align:center; background-color:teal; color:white; border-radius: 15px 50px; \">THE END</h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
